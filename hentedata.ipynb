{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hente og lagre data fra JSON data fra ulike APIer, lagre som CSV og JSON filer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\silje\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\silje\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasql\n",
      "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from pandasql) (2.2.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from pandasql) (2.2.3)\n",
      "Collecting sqlalchemy (from pandasql)\n",
      "  Downloading sqlalchemy-2.0.39-cp313-cp313-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\silje\\appdata\\roaming\\python\\python313\\site-packages (from pandas->pandasql) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from pandas->pandasql) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from pandas->pandasql) (2025.1)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy->pandasql)\n",
      "  Downloading greenlet-3.1.1-cp313-cp313-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting typing-extensions>=4.6.0 (from sqlalchemy->pandasql)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\silje\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->pandasql) (1.17.0)\n",
      "Downloading sqlalchemy-2.0.39-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp313-cp313-win_amd64.whl (299 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: pandasql\n",
      "  Building wheel for pandasql (pyproject.toml): started\n",
      "  Building wheel for pandasql (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26844 sha256=2d89f00173fa56568b8dbab5aa0fe05725f65dcf968ad64f25d68a9593d5e3ab\n",
      "  Stored in directory: c:\\users\\silje\\appdata\\local\\pip\\cache\\wheels\\b4\\d0\\8c\\a6b366870bf041849cd96e03b71641e082f8d6456269b603b7\n",
      "Successfully built pandasql\n",
      "Installing collected packages: typing-extensions, greenlet, sqlalchemy, pandasql\n",
      "Successfully installed greenlet-3.1.1 pandasql-0.7.3 sqlalchemy-2.0.39 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\silje\\onedrive\\dokumenter\\ny mappe (2)\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key2 = os.getenv(\"API_KEY2\")\n",
    "url = os.getenv(\"DATABASER_URL\")\n",
    "\n",
    "#hente og importere data fra API\n",
    "#Bruker KEY og env slik at dataene ikke skal blir publisert på GIT\n",
    "\n",
    "url = \"https://api.openweathermap.org/data/2.5/weather?q={Trondheim}&appid={your api key}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F4a21c4f5ca42fa7590a6443bd594c13\n",
      "Feil ved henting av data for 2025-02-16: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-17: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-18: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-19: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-20: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-21: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-22: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-23: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-24: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-25: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-26: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-27: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-02-28: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-01: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-02: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-03: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-04: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-05: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-06: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-07: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-08: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-09: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-10: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-11: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-12: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-13: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-14: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-15: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Feil ved henting av data for 2025-03-16: 404\n",
      "{\"cod\":\"404\",\"message\":\"Internal error\"}\n",
      "Data lagret som miljodata.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#Last inn API-nøkkel fra .env\n",
    "load_dotenv()\n",
    "api_key2 = os.getenv(\"API_KEY2\") #gjør dette til en env-fil\n",
    "print(api_key2)  # Sjekk om API-nøkkelen er hentet riktig\n",
    "base_URL2 = os.getenv(\"DATABASE_URL2\")\n",
    "\n",
    "\n",
    "city = \"Trondheim\"\n",
    "lat = 63.4308 #breddegrad Trondheim\n",
    "lon = 10.4034 #lengdegrad Trondheim\n",
    "\n",
    "#beregner dato en uke tilbake fra idag\n",
    "start_date = datetime(2025, 2, 16)\n",
    "end_date = datetime(2025, 3, 16)\n",
    "\n",
    "vaerdata = []\n",
    "\n",
    "current_date = start_date       \n",
    "\n",
    "while current_date <= end_date:\n",
    "    date_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "    timestamp = int(current_date.timestamp())\n",
    "    \n",
    "    #URL for timemachine API\n",
    "    url2 = f\"{base_URL2}/data/2.5/onecall/timemachine?lat={lat}&lon={lon}&dt={timestamp}&appid={api_key2}\"\n",
    "\n",
    "    #sender forespørsel til OpenWeatherMap API\n",
    "    response = requests.get(url2)\n",
    "\n",
    "\n",
    "\n",
    "#HEADERS = {\"User-Agent\": \"Prosjektet/2.0 (friha@stud.ntnu.no)\"}  \n",
    "#response = requests.get(url2, headers= HEADERS)\n",
    "\n",
    "    if response.status_code ==200:\n",
    "        data = response.json()\n",
    "\n",
    "        #legg data til vaerdata_listen\n",
    "        vaerdata.append(data)\n",
    "\n",
    "    else:\n",
    "        print(f\"Feil ved henting av data for {date_str}: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "    #Gå til neste dag\n",
    "    current_date += timedelta(days = 1)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#Lagrer til en JSON-fil\n",
    "with open(\"miljodata.json\", \"w\", encoding = \"utf-8\") as f:  #åpner og oppretter en fil for skriving, med gitt navn. Hvis filen allerede finnes, vil den bli overskrevet. \n",
    "        json.dump(vaerdata, f, indent = 4, ensure_ascii=False )     #Tar et python-objekt og skriver det til en fil i JSON-format. Indent= 4 gir mellomrom for hvert nivå. Spesialtegn blir skrevet ut riktig med ascii\n",
    "\n",
    "print(\"Data lagret som miljodata.json\")  \n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#sjekker hva slags data som er lagret\n",
    "\n",
    "with open(\"miljodata.json\", \"r\", encoding = \"utf-8\") as f:  #åpner filen for lesing, encoding sikrer at alle tegn håndteres korrekt\n",
    "    data = json.load(f) #leser  JSON-data fra filen f og konverterer den til et python-objekt som lagres i variabelen data\n",
    "\n",
    "print(json.dumps(data, indent=4)) #skriver ut innholdet i filen på en lesbar måte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feil ved henting av data: 404\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "lat = 63.4308 #breddegrad Trondheim\n",
    "lon = 10.4034 #lengdegrad Trondheim\n",
    "start_date = \"2025-03-09\"\n",
    "end_date = \"2025-03-16\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url1= f\"https://api.met.no/weatherapi/climatehistory/v1/daily?lat={lat}&lon={lon}&start={start_date}&end={end_date}\"#api med lat= breddegrad og lon = lengdegrad i Trondheim\n",
    "HEADERS = {\"User-Agent\": \"Prosjektet/2.0 (siljnord@stud.ntnu.no)\"}  \n",
    "response = requests.get(url1, headers= HEADERS)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "else: \n",
    "    print(f\"feil ved henting av data: {response.status_code}\")\n",
    "    data = None\n",
    "\n",
    "#Henter data fra en uke tilbake i tid\n",
    "if data: \n",
    "    #liste som skal inneholde værdata for den siste uken\n",
    "    trondheim_vaerdata = []\n",
    "\n",
    "    #beregner dato for en uke tilbake\n",
    "\n",
    "    one_week_ago = datetime.utcnow() - timedelta(days = 7)\n",
    "\n",
    "\n",
    "    for forecast in data.get(\"properties\",{}).get(\"timeseries\", []):\n",
    "        tidspunkt = forecast.get(\"time\", \"ukjent_tidspunkt\")\n",
    "\n",
    "        #konverterer tidspunkt til en datetime\n",
    "        tidspunkt_dt = datetime.strptime(tidspunkt, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        #sjekker at tidspunktet er innenfor den siste uken\n",
    "        if tidspunkt_dt >= one_week_ago:\n",
    "            instant_data = forecast.get(\"data\", {}).get(\"instant\", {}).get(\"details\", {})\n",
    "\n",
    "            temperatur = instant_data.get(\"air_temperature\", \"Data mangler\")\n",
    "            vindhastighet = instant_data.get(\"wind_speed\", \"Data mangler\")\n",
    "            \n",
    "            nedbor = forecast.get(\"data\", {}).get(\"next_1_hours\", {}).get(\"details\", {}).get(\"precipitation_amount\",0)\n",
    "\n",
    "        #legg til data i listen\n",
    "        trondheim_vaerdata.append({\n",
    "            \"tidspunkt\": tidspunkt, \n",
    "            \"temperatur\": temperatur, \n",
    "            \"vindhastighet\": vindhastighet,\n",
    "            \"nedbor\": nedbor\n",
    "        })\n",
    "\n",
    "        #lagrer værdata til fil \n",
    "        with open (\"trondheim_vaerdata.json\", \"w\", encoding = \"utf-8\") as f:\n",
    "            json.dump(trondheim_vaerdata, f, indent= 4, ensure_ascii= False)\n",
    "\n",
    "        print(\"Data lagret som trondheim_vaerdata.json\")\n",
    "\n",
    "\n",
    "        #skriv ut data\n",
    "        with open (\"trondheim_vaerdata.json\", \"r\", encoding = \"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        print(json.dumps(data, indent=4, ensure_ascii = False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
